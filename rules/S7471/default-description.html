<div class="sect1">
<h2 id="_description">Description</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This rule raises an issue when a PySpark <code>SparkContext</code> or <code>SparkSession</code> is initialized without explicitly specifying both the <code>master</code> URL and <code>appName</code> parameters.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_why_is_this_an_issue">Why is this an issue?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>When initializing a new <code>SparkContext</code> in PySpark, it is essential to specify both the master URL and the application name. The master URL determines the cluster to connect to, while the application name is used to identify your application on the cluster. Since when creating a <code>SparkSession</code> the <code>SparkContext</code> can be created implicitly, it is also important to set these parameters when creating a new <code>SparkSession</code>.</p>
</div>
<div class="paragraph">
<p>Failing to set these parameters can lead to unexpected behavior, such as connecting to an unintended cluster or having difficulty identifying your application in the Spark UI.</p>
</div>
<div class="paragraph">
<p>A good default for the master URL for local development is <code>local[*]</code>, which uses all available cores on your machine. Alternatively, you can use <code>local[n]</code>, where <code>n</code> is the specific number of cores you want to allocate. However, in production environments, you should specify the actual cluster URL (e.g., <code>spark://host:port</code> or <code>yarn</code>).</p>
</div>
<div class="sect2">
<h3 id="_exceptions">Exceptions</h3>
<div class="paragraph">
<p>When using PySpark with AWS Glue, the master and name parameters are usually not set, since AWS Glue manages these configurations automatically.
Because of this, the rule doesn&#8217;t raise if <code>awsglue</code> has been imported.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">from pyspark.context import SparkContext
from awsglue.context import GlueContext

sc = SparkContext() # Compliant: used in the context of awsglue code
glueContext = GlueContext(sc)</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_how_to_fix_it">How to fix it</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To fix this issue, always provide both the <code>master</code> and <code>appName</code> parameters when creating a <code>SparkContext</code> or <code>SparkSession</code>, either directly or through a <code>SparkConf</code> object.</p>
</div>
<div class="sect2">
<h3 id="_code_examples">Code examples</h3>
<div class="sect3">
<h4 id="_noncompliant_code_example">Noncompliant code example</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">from pyspark import SparkContext

sparkContext = SparkContext() # Noncompliant: neither master nor appName are specified

sparkSession = SparkSession.builder.getOrCreate() # Noncompliant: neither master nor appName are specified</code></pre>
</div>
</div>
<div class="sect4">
<h5 id="_compliant_solution">Compliant solution</h5>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">from pyspark import SparkContext

sparkContext = SparkContext(master="local[2]", appName="MySparkApplication") # Compliant: providing both parameters explicitly

sparkSession = SparkSession.builder\
    .master("local[2]")\
    .appName("MySparkApplication")\
    .getOrCreate()</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_resources">Resources</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_documentation">Documentation</h3>
<div class="ulist">
<ul>
<li>
<p>PySpark Documentation - <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkContext.html">pyspark.SparkContext</a></p>
</li>
<li>
<p>PySpark Documentation - <a href="https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.SparkConf.html">pyspark.SparkConf</a></p>
</li>
<li>
<p>PySpark Documentation - <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.SparkSession.html">pyspark.sql.SparkSession</a></p>
</li>
<li>
<p>Apache Spark Documentation - <a href="https://spark.apache.org/docs/latest/submitting-applications.html#master-urls">Master URLs</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_implementation_specification">Implementation Specification</h2>
<div class="sectionbody">
<div class="paragraph">
<p>(visible only on this page)</p>
</div>
<div class="sect2">
<h3 id="_message">Message</h3>
<div class="paragraph">
<p>Specify both "master" and "appName" parameters when initializing a SparkContext.</p>
</div>
</div>
<div class="sect2">
<h3 id="_highlighting">Highlighting</h3>
<div class="paragraph">
<p>The SparkContext constructor call.</p>
</div>
</div>
<div class="sect2">
<h3 id="_quickfix">Quickfix</h3>
<div class="ulist">
<ul>
<li>
<p>For a missing master: add master="local[*]" as parameter.</p>
</li>
<li>
<p>For a missing appName: add appName="SparkApplication" as parameter.</p>
</li>
</ul>
</div>
</div>
</div>
</div>