<div class="sect1">
<h2 id="_description">Description</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This rule raises an issue when a PySpark DataFrame is used multiple times without being cached using the <code>.cache()</code> method.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_why_is_this_an_issue">Why is this an issue?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>In Spark, transformations on DataFrames are lazy, meaning they are not executed until an action (like <code>count</code>, <code>collect</code>, etc.) is called. If you perform multiple actions on the same <code>DataFrame</code> without caching or persisting it, Spark will recompute the entire lineage of transformations for each action. By caching or persisting the DataFrame, you store the result of the transformations, avoiding the need to recompute them each time.</p>
</div>
<div class="paragraph">
<p>For this reason, DataFrames that are reused across multiple functions or operations should be cached using the <code>.cache()</code> method. This practice helps to prevent unnecessary recomputations, which can be resource-intensive and time-consuming. By caching <code>DataFrames</code>, you can leverage Spark&#8217;s in-memory computation capabilities to enhance performance. This also reduces the need to read data from the original source repeatedly.</p>
</div>
<div class="paragraph">
<p>If the DataFrame is too large to fit into memory, consider using .persist() with an appropriate storage level instead of .cache().</p>
</div>
<div class="paragraph">
<p>This rule will trigger an issue when 3 or more actions are performed on the DataFrame without it being cached, or when an action is performed within a loop.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_how_to_fix_it">How to fix it</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To fix this issue, make sure to either cache or persist <code>DataFrames</code> that are reused multiple times.</p>
</div>
<div class="sect2">
<h3 id="_code_examples">Code examples</h3>
<div class="sect3">
<h4 id="_noncompliant_code_example">Noncompliant code example</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Example").getOrCreate()

df = spark.read.csv("data.csv") # Noncompliant

def transform_data_1(df):
    # Some transformations
    return df.filter(df['value'] &gt; 10)

def transform_data_2(df):
    # Some other transformations
    return df.groupBy('category').count()

def transform_data_3(df):
    # Some other transformations
    return df.groupBy('customerID').count()

result1 = transform_data_1(df)
result2 = transform_data_2(df)
result3 = transform_data_3(df)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compliant_solution">Compliant solution</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Example").getOrCreate()

df = spark.read.csv("data.csv").cache() # Compliant

def transform_data_1(df):
    # Some transformations
    return df.filter(df['value'] &gt; 10)

def transform_data_2(df):
    # Some other transformations
    return df.groupBy('category').count()

def transform_data_3(df):
    # Some other transformations
    return df.groupBy('customerID').count()

result1 = transform_data_1(df)
result2 = transform_data_2(df)
result3 = transform_data_3(df)</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_resources">Resources</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_documentation">Documentation</h3>
<div class="ulist">
<ul>
<li>
<p>Spark documentation - <a href="https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.DataFrame.cache.html">pyspark.sql.DataFrame.cache</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_articles_blog_posts">Articles &amp; blog posts</h3>
<div class="ulist">
<ul>
<li>
<p>Spark by Example - <a href="https://sparkbyexamples.com/pyspark/pyspark-cache-explained/">PySpark cache explained</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_implementation_specification">Implementation Specification</h3>

</div>
<div class="sect2">
<h3 id="_message">Message</h3>
<div class="paragraph">
<p>Consider caching or persisting this DataFrame.</p>
</div>
</div>
<div class="sect2">
<h3 id="_highlighting">Highlighting</h3>
<div class="paragraph">
<p>The API call reading and creating the initial DataFrame.</p>
</div>
</div>
<div class="sect2">
<h3 id="_quickfix">Quickfix</h3>
<div class="paragraph">
<p>We can add the <code>.cache()</code> method to the DataFrame.
Quick fix message: <code>Cache the DataFrame</code>.</p>
</div>
</div>
</div>
</div>