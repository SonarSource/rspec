This rule raises an issue when an Scikit-Learn Pipeline is created without specifying the `memory` argument.

== Why is this an issue?

Specifying the `memory` argument in a Scikit-Learn Pipeline allows the pipeline to cache the transformers. This can be useful when the transformers are expensive to compute or if the dataset is large, and can save time when the pipeline is fitted multiple times.

== How to fix it
Specify the `memory` argument when creating a Scikit-Learn Pipeline.

=== Code examples

==== Noncompliant code example

[source,text,diff-id=1,diff-type=noncompliant]
----
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LinearDiscriminantAnalysis())
])
----

==== Compliant solution

[source,text,diff-id=1,diff-type=compliant]
----
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('classifier', LinearDiscriminantAnalysis())
], memory="cache_folder")
----


=== Pitfalls
If the pipeline is used with different datasets, the cache may not be helpful and can consume a lot of space.
This is true when using `sklearn.model_selection.HalvingGridSearchCV` or `sklearn.model_selection.HalvingRandomSearchCV` because the size of the dataset changes every iteration when using the default configuration.

== Implementation specification
Check if the parameter is provided without needing to check the value.
Might be able to make a quickfix to add `memory=None` to make it less painful to fix.

Issue location : right before the parenthesis or the parenthesis itself.

== Resources
=== Documentation
* Scikit-Learn documentation - https://scikit-learn.org/stable/modules/compose.html#caching-transformers-avoid-repeated-computation[Pipeline]