<div class="sect1">
<h2 id="_description">Description</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This rule raises an issue when the <code>axis</code>/<code>dim`</code> argument is not provided to reduction operations.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_why_is_this_an_issue">Why is this an issue?</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_tensorflow">TensorFlow</h3>
<div class="paragraph">
<p>The result of reduction operations (i.e. <code>tf.math.reduce_sum</code>, <code>tf.math.reduce_std</code>, <code>torch.sum</code>, <code>torch.mean</code>, etc&#8230;&#8203;),
highly depends on the shape of the Tensor provided.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import tensorflow as tf

x = tf.constant([[1, 1, 1], [1, 1, 1]])
tf.math.reduce_sum(x)</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the example above the reduction of the 2 dimensional array will return the value <code>6</code> as all the elements are added together.
By default TensorFlow&#8217;s reduction operations are applied across all axis. When specifying an axis the result will be completely different.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import tensorflow as tf

x = tf.constant([[1, 1, 1], [1, 1, 1]])
tf.math.reduce_sum(x, axis=0)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here the result will be <code>[2,2,2]</code> as the reduction is applied only on the axis 0.</p>
</div>
<div class="paragraph">
<p>TensorFlow&#8217;s default behavior can be confusing, especially when the reducing array of different shapes.</p>
</div>
<div class="paragraph">
<p>Considering the following example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import tensorflow as tf

x = tf.constant([[1], [2]])
y = tf.constant([1, 2])
tf.math.reduce_sum(x + y)</code></pre>
</div>
</div>
<div class="paragraph">
<p>Here the result will be <code>12</code> instead of the <code>6</code> that could be expected. This is because the implicit broadcasting reshapes the
first array to <code>[[1,1], [2,2]]</code> which is then added to the <code>y</code> array <code>[1,2]</code> resulting in <code>[[2,3], [3,4]]</code>. As the
reduction happen across all dimensions the result is then <code>2 + 3 + 3 + 4 = 12</code>. It is not clear by looking at the example
if this was intentional or if the user made a mistake.</p>
</div>
<div class="paragraph">
<p>This is why a good practice is to always specify the axis on which to perform the reduction.</p>
</div>
<div class="paragraph">
<p>For example:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import tensorflow as tf

x = tf.constant([[1], [2]])
y = tf.constant([1, 2])
tf.math.reduce_sum(x + y, axis=0)</code></pre>
</div>
</div>
<div class="paragraph">
<p>In the example above, specifying the axis clarifies the intent, as the result now is <code>[5, 7]</code>. If the intent was to effectively
reduce across all dimensions the user should provide the list of axis <code>axis=[0,1]</code>
or clearly state the default behavior should be applied with <code>axis=None</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="_the_pytorch_equivalent">The PyTorch equivalent</h3>
<div class="paragraph">
<p>The same behavior occurs in PyTorch, but the argument is called <code>dim</code> instead of <code>axis</code>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_how_to_fix_it_in_tensorflow">How to fix it in TensorFlow</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To fix this issue provide the axis argument when using a TensorFlow reduction operation such as <code>tf.math.reduce_sum</code>, <code>tf.math.reduce_prod</code>, <code>tf.math.reduce_mean</code>, etc&#8230;&#8203;</p>
</div>
<div class="sect2">
<h3 id="_code_examples">Code examples</h3>
<div class="sect3">
<h4 id="_noncompliant_code_example">Noncompliant code example</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import tensorflow as tf

x = tf.constant([[1, 1, 1], [1, 1, 1]])
tf.math.reduce_sum(x) # Noncompliant: the axis arguments defaults to None</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compliant_solution">Compliant solution</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import tensorflow as tf

x = tf.constant([[1, 1, 1], [1, 1, 1]])
tf.math.reduce_sum(x, axis=0) # Compliant: the reduction will happen only on the axis 0, resulting in `[2,2,2]`</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_how_to_fix_it_in_pytorch">How to fix it in PyTorch</h2>
<div class="sectionbody">
<div class="paragraph">
<p>To fix this issue provide the dim argument when using a PyTorch reduction operation such as <code>torch.sum</code>, <code>torch.prod</code>, <code>torch.mean</code>, etc&#8230;&#8203;</p>
</div>
<div class="sect2">
<h3 id="_code_examples_2">Code examples</h3>
<div class="sect3">
<h4 id="_noncompliant_code_example_2">Noncompliant code example</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch

x = torch.tensor([[1, 1, 1], [1, 1, 1]])
torch.sum(x) # Noncompliant: the dim argument defaults to None</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compliant_solution_2">Compliant solution</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch

x = torch.tensor([[1, 1, 1], [1, 1, 1]])
torch.sum(x, dim=None) # Compliant: all dimensions will be reduced</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_resources">Resources</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_documentation">Documentation</h3>
<div class="ulist">
<ul>
<li>
<p>TensorFlow Documentation - <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_max">tf.math.reduce_max reference</a></p>
</li>
<li>
<p>TensorFlow Documentation - <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean">tf.math.reduce_mean reference</a></p>
</li>
<li>
<p>TensorFlow Documentation - <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_min">tf.math.reduce_min reference</a></p>
</li>
<li>
<p>TensorFlow Documentation - <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_prod">tf.math.reduce_prod reference</a></p>
</li>
<li>
<p>TensorFlow Documentation - <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_std">tf.math.reduce_std reference</a></p>
</li>
<li>
<p>TensorFlow Documentation - <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_sum">tf.math.reduce_sum reference</a></p>
</li>
<li>
<p>TensorFlow Documentation - <a href="https://www.tensorflow.org/api_docs/python/tf/math/reduce_variance">tf.math.reduce_variance reference</a></p>
</li>
<li>
<p>PyTorch Documentation - <a href="https://pytorch.org/docs/stable/torch.html#reduction-ops">Reduction operations</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_articles_blog_posts">Articles &amp; blog posts</h3>
<div class="ulist">
<ul>
<li>
<p>Vahidk Developers Guide - <a href="https://github.com/vahidk/EffectiveTensorflow?tab=readme-ov-file#broadcasting-the-good-and-the-ugly">Broadcasting the good and the ugly</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>