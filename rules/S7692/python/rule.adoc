This rule raises an issue when tensors are flipped using manual indexing operations with negative steps (e.g., `tensor[::-1]`) instead of the built-in `torch.flip()` function.

== Why is this an issue?

Manual tensor flipping using negative indexing like `tensor[::-1]` or `tensor[:, :, :, ::-1]` is less readable and maintainable compared to using PyTorch's built-in `torch.flip()` function.

The manual approach has several drawbacks:

* **Poor readability**: The intent to flip a tensor is not immediately clear from the indexing syntax
* **Error-prone**: It's easy to make mistakes with the number of colons and dimensions
* **Hard to maintain**: Changes to tensor dimensions require updating the indexing pattern
* **Less explicit**: The specific dimensions being flipped are not obvious

The `torch.flip()` function was specifically designed for this purpose and provides a clear, explicit way to flip tensors along specified dimensions. It takes the tensor and a list of dimensions to flip, making the code self-documenting and easier to understand.

=== What is the potential impact?

Using manual indexing for tensor flipping reduces code readability and maintainability. While it doesn't cause runtime errors, it makes the code harder to understand and more prone to mistakes during modifications. The built-in function is also potentially more optimized for performance.

=== How to fix in PyTorch?

Replace manual tensor flipping with negative indexing by using `torch.flip()`. Specify the tensor and the dimensions to flip as a list.

==== Non-compliant code example

[source,python,diff-id=1,diff-type=noncompliant]
----
import torch

# Manual tensor flipping along last dimension
flipped_tensor = tensor[:, :, :, ::-1]  # Noncompliant

# Manual flipping along first dimension
flipped_tensor = tensor[::-1]  # Noncompliant
----

==== Compliant code example

[source,python,diff-id=1,diff-type=compliant]
----
import torch

# Using torch.flip along last dimension (dimension 3)
flipped_tensor = torch.flip(tensor, dims=[3])

# Using torch.flip along first dimension (dimension 0)
flipped_tensor = torch.flip(tensor, dims=[0])
----

For flipping multiple dimensions, you can specify multiple dimensions in the `dims` parameter.

==== Non-compliant code example

[source,python,diff-id=2,diff-type=noncompliant]
----
import torch

# Manual flipping along multiple dimensions
flipped_tensor = tensor[::-1, :, ::-1]  # Noncompliant
----

==== Compliant code example

[source,python,diff-id=2,diff-type=compliant]
----
import torch

# Using torch.flip along multiple dimensions
flipped_tensor = torch.flip(tensor, dims=[0, 2])
----

=== Documentation

 * torch.flip documentation - https://pytorch.org/docs/stable/generated/torch.flip.html[Official PyTorch documentation for the torch.flip function]
 * PyTorch tensor indexing - https://pytorch.org/docs/stable/tensor_view.html[Documentation on tensor indexing and slicing operations]

