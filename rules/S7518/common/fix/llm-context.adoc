==== Explicitly stem the LLM context

While designing an LLM application, and particularly at the stage where you
design the system, developer and user prompts that are to be passed
to the model, keep the **principle of least privilege** in mind.

Start by providing any external third-party or user with the least amount of
capabilities or information, and only level up their privileges
**intentionally**, e.g. when a situation (like tool calls) requires it.

Another short-term hardening approach is to add AI guardrails to your LLM, such
as additional prompts forbidding the model from generating certain outputs. +
While creating these, keep in mind that deny-list-based filtering can be complex
to maintain in the long-term **and** can most of the time be creatively
bypassed.

