== How to fix it in OpenAI

=== Code examples

include::../../code-rationale.adoc[]

==== Noncompliant code example

[source,python,diff-id=21,diff-type=noncompliant]
----
app = Flask(__name__)
client = OpenAI()

@app.route('/example')
def example()
    payload = request.get_json()
    prompt_text = payload.get('prompt_text')
    system_text = payload.get('sys_text')

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        max_tokens=2048,
        messages=[
            {"role": "system", "content": system_text},
            {"role": "user", "content": prompt_text}
        ]
    )
----

== Compliant Solution

[source,python,diff-id=21,diff-type=compliant]
----
app = Flask(__name__)
client = OpenAI()

@app.route('/example')
def example()
    payload = request.get_json()
    prompt_text = payload.get('prompt_text')

    response = client.chat.completions.create(
        model="gpt-3.5-turbo",
        max_tokens=2048,
        messages=[
            {"role": "system", "content": "You are 'ExampleBot', a professional AI assistant [...]"},
            {"role": "user", "content": prompt_text}
        ]
    )
----

=== How does this work?

include::../../common/fix/llm-context.adoc[]
