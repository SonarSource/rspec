<div class="sect1">
<h2 id="_description">Description</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This rule raises an issue when <code>torch.cat()</code> is used inside loops to incrementally build tensors, especially when starting with empty tensors.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_why_is_this_an_issue">Why is this an issue?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Incremental tensor concatenation using <code>torch.cat()</code> in loops creates significant performance and correctness problems.</p>
</div>
<div class="paragraph">
<p>Each call to <code>torch.cat()</code> creates a new tensor and copies all existing data. When done repeatedly in a loop, this results in quadratic time complexity O(n²) instead of linear O(n). For example, concatenating 1000 tensors this way performs roughly 500,000 copy operations instead of just 1000.</p>
</div>
<div class="paragraph">
<p>Starting with empty tensors (<code>torch.Tensor()</code>) introduces additional issues. Empty tensors have undefined dimensions and may use different data types or devices than the tensors being concatenated. This can lead to runtime errors or unexpected tensor shapes.</p>
</div>
<div class="paragraph">
<p>The repeated memory allocations and deallocations also create unnecessary garbage collection pressure, further degrading performance in memory-constrained environments.</p>
</div>
<div class="sect2">
<h3 id="_what_is_the_potential_impact">What is the potential impact?</h3>
<div class="paragraph">
<p>Performance degradation becomes severe with larger datasets, potentially making training or inference impractically slow. Memory usage increases significantly due to intermediate tensor copies. Runtime errors may occur when concatenating with empty tensors due to dimension or type mismatches.</p>
</div>
</div>
<div class="sect2">
<h3 id="_how_to_fix">How to fix?</h3>
<div class="paragraph">
<p>Collect tensors in a Python list during the loop, then use <code>torch.stack()</code> for a new dimension or <code>torch.cat()</code> once at the end. This reduces complexity from O(n²) to O(n).</p>
</div>
<div class="sect3">
<h4 id="_non_compliant_code_example">Non-compliant code example</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch

# Inefficient: incremental concatenation
batched_tensors = torch.Tensor()  # Noncompliant

for i in range(100):
    tensor = torch.rand(10, 20)
    batched_tensors = torch.cat((batched_tensors, tensor))  # Noncompliant</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compliant_code_example">Compliant code example</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch

# Efficient: collect then stack/concatenate once
tensor_list = []

for i in range(100):
    tensor = torch.rand(10, 20)
    tensor_list.append(tensor)

batched_tensors = torch.stack(tensor_list)  # Shape: [100, 10, 20]</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_documentation">Documentation</h3>
<div class="ulist">
<ul>
<li>
<p>PyTorch torch.cat documentation - <a href="https://pytorch.org/docs/stable/generated/torch.cat.html">Official documentation for torch.cat function</a></p>
</li>
<li>
<p>PyTorch torch.stack documentation - <a href="https://pytorch.org/docs/stable/generated/torch.stack.html">Official documentation for torch.stack function</a></p>
</li>
<li>
<p>PyTorch Performance Tuning Guide - <a href="https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html">Best practices for optimizing PyTorch performance</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>