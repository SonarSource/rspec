<div class="sect1">
<h2 id="_description">Description</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This rule flags code that uses numerically unstable mathematical operations instead of PyTorch&#8217;s specialized numerically stable functions.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_why_is_this_an_issue">Why is this an issue?</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Mathematical operations involving floating-point arithmetic can suffer from precision loss and catastrophic cancellation, particularly when dealing with values close to critical points. Two common patterns that exhibit these issues are:</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><code>torch.log(1 + x)</code> - When <code>x</code> is close to zero, adding it to 1 can result in precision loss</p>
</li>
<li>
<p><code>torch.exp(x) - 1</code> - When <code>x</code> is close to zero, the subtraction can cause catastrophic cancellation</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>In floating-point arithmetic, these operations can lead to significant numerical errors:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>For <code>torch.log(1 + x)</code> when <code>x</code> is very small (like <code>1e-15</code>), the computation <code>1 + x</code> might not accurately represent the true mathematical result due to the limited number of significant digits that can be represented.</p>
</li>
<li>
<p>For <code>torch.exp(x) - 1</code> when <code>x</code> is close to zero, <code>torch.exp(x)</code> returns a value very close to 1.0, and subtracting 1 from this value can result in significant loss of precision.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>PyTorch provides specialized functions that are designed to compute these expressions accurately:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>torch.log1p(x)</code> computes <code>log(1 + x)</code> accurately for small values of <code>x</code></p>
</li>
<li>
<p><code>torch.expm1(x)</code> computes <code>exp(x) - 1</code> accurately for small values of <code>x</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These functions use specialized algorithms that avoid the problematic intermediate computations, maintaining precision even when dealing with values close to critical points.</p>
</div>
<div class="paragraph">
<p>This numerical instability can propagate through calculations and significantly affect the accuracy of machine learning models, particularly in scenarios involving:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Small gradients during training</p>
</li>
<li>
<p>Probability calculations with values close to critical points</p>
</li>
<li>
<p>Mathematical operations in activation functions</p>
</li>
<li>
<p>Loss function computations</p>
</li>
<li>
<p>Iterative optimization algorithms</p>
</li>
</ul>
</div>
<div class="sect2">
<h3 id="_what_is_the_potential_impact">What is the potential impact?</h3>
<div class="paragraph">
<p>Using numerically unstable mathematical operations instead of their stable counterparts can lead to:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Reduced accuracy in mathematical computations</p>
</li>
<li>
<p>Potential instability in machine learning model training</p>
</li>
<li>
<p>Incorrect results in probability calculations</p>
</li>
<li>
<p>Accumulation of numerical errors in iterative algorithms</p>
</li>
<li>
<p>Inaccurate gradient calculations during training</p>
</li>
<li>
<p>Convergence issues in optimization algorithms</p>
</li>
<li>
<p>Reduced model performance due to accumulated numerical errors</p>
</li>
<li>
<p>Inconsistent results across different hardware or precision settings</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_how_to_fix">How to fix?</h3>
<div class="paragraph">
<p>Replace the numerically unstable patterns with their stable PyTorch equivalents:</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Replace <code>torch.log(1 + x)</code> with <code>torch.log1p(x)</code></p>
</li>
<li>
<p>Replace <code>torch.exp(x) - 1</code> with <code>torch.expm1(x)</code></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>These specialized functions compute the same mathematical results but with better numerical stability for values near critical points.</p>
</div>
<div class="sect3">
<h4 id="_non_compliant_code_examples">Non-compliant code examples</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch

# Numerically unstable logarithm computation
result1 = torch.log(1 + x)  # Noncompliant

# Numerically unstable exponential computation
result2 = torch.exp(x) - 1  # Noncompliant</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_compliant_code_examples">Compliant code examples</h4>
<div class="listingblock">
<div class="content">
<pre class="highlight"><code class="language-python" data-lang="python">import torch

# Numerically stable logarithm computation
result1 = torch.log1p(x)

# Numerically stable exponential computation
result2 = torch.expm1(x)</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_documentation">Documentation</h3>
<div class="ulist">
<ul>
<li>
<p>PyTorch torch.log1p documentation - <a href="https://pytorch.org/docs/stable/generated/torch.log1p.html">Official PyTorch documentation for the log1p function</a></p>
</li>
<li>
<p>PyTorch torch.expm1 documentation - <a href="https://pytorch.org/docs/stable/generated/torch.expm1.html">Official PyTorch documentation for the expm1 function</a></p>
</li>
<li>
<p>NumPy log1p documentation - <a href="https://numpy.org/doc/stable/reference/generated/numpy.log1p.html">NumPy documentation explaining the numerical stability benefits of log1p</a></p>
</li>
<li>
<p>NumPy expm1 documentation - <a href="https://numpy.org/doc/stable/reference/generated/numpy.expm1.html">NumPy documentation explaining the numerical stability benefits of expm1</a></p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_standards">Standards</h3>
<div class="ulist">
<ul>
<li>
<p>IEEE 754: Standard for Floating-Point Arithmetic - <a href="https://standards.ieee.org/ieee/754/6210/">IEEE standard that defines floating-point arithmetic and the precision issues that specialized functions help address</a></p>
</li>
</ul>
</div>
</div>
</div>
</div>