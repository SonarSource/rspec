This rule raises an issue when a single Python file contains multiple distinct PyTorch components like model definitions, training functions, evaluation functions, and data processing utilities, typically when the file exceeds reasonable size limits.

== Why is this an issue?

Large, monolithic PyTorch files create several maintenance challenges that grow worse as projects scale.

When everything lives in one file, it becomes difficult to locate specific functionality. A developer looking for a model definition might have to scroll through hundreds of lines of training code, data preprocessing, and utility functions. This cognitive overhead slows down development and increases the chance of errors.

Testing becomes problematic because functions and classes are tightly coupled within the same namespace. Unit testing individual components requires importing the entire file, which may trigger unwanted side effects or dependencies. This makes it harder to write focused, reliable tests.

Collaboration suffers when multiple developers work on the same monolithic file. Version control conflicts become more frequent and harder to resolve when changes to the model architecture, training loop, and data processing all happen in the same file.

Code reusability is limited because extracting a model or utility function for use in another project requires copying code and manually resolving dependencies. Well-organized packages make it easy to import specific components where needed.

The problem compounds in machine learning projects because they naturally involve distinct concerns: data loading and preprocessing, model architecture definition, training procedures, evaluation metrics, and often multiple model variants or experiments.

=== What is the potential impact?

Poor code organization leads to increased development time, higher bug rates, and reduced team productivity. Large monolithic files make debugging more difficult and discourage code reuse across projects. In production environments, this can result in deployment issues and make it harder to maintain and update models.

=== How to fix?


Organize your PyTorch project by separating different concerns into logical modules. Create separate files for models, training logic, evaluation functions, and data processing. Use packages to group related functionality together.

==== Non-compliant code example

[source,python,diff-id=1,diff-type=noncompliant]
----
# main.py - Everything in one file
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

class MyModel(nn.Module):  # Noncompliant
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(10, 1)
    
    def forward(self, x):
        return self.linear(x)

def train_model(model, dataloader):  # Noncompliant
    optimizer = torch.optim.Adam(model.parameters())
    for batch in dataloader:
        # training logic
        pass

def evaluate_model(model, dataloader):  # Noncompliant
    with torch.no_grad():
        for batch in dataloader:
            # evaluation logic
            pass

def preprocess_data(raw_data):  # Noncompliant
    # data preprocessing logic
    return processed_data

if __name__ == '__main__':
    # main execution logic
    pass
----

==== Compliant code example

[source,python,diff-id=1,diff-type=compliant]
----
# models/my_model.py
import torch.nn as nn

class MyModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.linear = nn.Linear(10, 1)
    
    def forward(self, x):
        return self.linear(x)

# training/trainer.py
import torch

def train_model(model, dataloader):
    optimizer = torch.optim.Adam(model.parameters())
    for batch in dataloader:
        # training logic
        pass

# evaluation/evaluator.py
import torch

def evaluate_model(model, dataloader):
    with torch.no_grad():
        for batch in dataloader:
            # evaluation logic
            pass

# data/preprocessing.py
def preprocess_data(raw_data):
    # data preprocessing logic
    return processed_data

# main.py
from models.my_model import MyModel
from training.trainer import train_model
from evaluation.evaluator import evaluate_model
from data.preprocessing import preprocess_data

if __name__ == '__main__':
    # main execution logic
    pass
----

=== Documentation

 * Python Modules Documentation - https://docs.python.org/3/tutorial/modules.html[Official Python documentation on organizing code into modules and packages]
 * PyTorch Project Structure Best Practices - https://pytorch.org/tutorials/beginner/saving_loading_models.html[PyTorch tutorial covering model organization and project structure]

=== Standards

 * PEP 8 - Style Guide for Python Code - https://peps.python.org/pep-0008/[Official Python style guide including recommendations for package and module organization]

